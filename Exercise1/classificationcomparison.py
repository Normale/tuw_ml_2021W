# -*- coding: utf-8 -*-
"""ClassificationComparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RXkRACD_EAwCewEqLLRYtihW2IrXvumE
"""

import pandas
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
import pathlib
import pandas as pd
import numpy as np
import pathlib
from tqdm import tqdm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import plotly.express as px
from sklearn import preprocessing
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.ensemble import RandomForestClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/drive")
# %cd /content/drive/My Drive/Machine Learning/

# Load the data
path = 'breast-cancer-diagnostic.shuf.lrn.csv'
dirPath = pathlib.Path(path)
df=pd.read_csv(dirPath)
#print(df.head())

# Set class-label from true/false to 0/1
df['class'] = df['class'].astype(int)

# Split into input and target variables
X = df.iloc[:, 2:]  # Remove the ID and Class columns
Y = df.iloc[:, 1]

# Scale data
x = X.values # returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
#scaler = preprocessing.StandardScaler()
#x_scaled = scaler.fit_transform(x)
x_scaled = min_max_scaler.fit_transform(x)
df_x_scaled = pd.DataFrame(x_scaled)
#print(df_x_scaled)

# prepare models
models = []
models.append(('KNN', KNeighborsClassifier(n_neighbors = 4, metric = 'euclidean')))
models.append(('RANDOM FORREST', RandomForestClassifier(n_estimators=10)))
models.append(('SVM', SVC(kernel='linear', C=1)))
# evaluate each model in turn
results = []
names = []
seed = 7
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=4, random_state=seed)
	cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)
# boxplot algorithm comparison
fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.ylabel('Accuracy')
plt.show()

# CHECK FOR IMBALANCE IN THE DATASET
len_true = len(Y[Y == 1])
len_false = len(Y[Y == 0])
print("IS THE DATASET IMBALANCED?\n")
print("Number of true: ",len_true)
print("Number of false: ",len_false)

trainX, testX, trainy, testy = train_test_split(df_x_scaled, Y, test_size=0.25, random_state=2)
# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(testy))]
# fit a model
model = svm.SVC(kernel='linear', C=1, random_state=42,probability=True)
model.fit(trainX, trainy)
# predict probabilities
lr_probs = model.predict_proba(testX)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:,1]
# calculate scores
ns_auc = roc_auc_score(testy, ns_probs)
lr_auc = roc_auc_score(testy, lr_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='SVM')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()