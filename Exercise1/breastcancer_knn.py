# -*- coding: utf-8 -*-
"""Breastcancer_KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUGVZM9QI-78CnDrAnoxGxSerQXovk5z
"""

import pandas as pd
import numpy as np
import pathlib
from tqdm import tqdm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import plotly.express as px
from sklearn import preprocessing
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.ensemble import RandomForestClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount("/content/drive")
# %cd /content/drive/My Drive/Machine Learning/

# Load the data
path = 'breast-cancer-diagnostic.shuf.lrn.csv'
dirPath = pathlib.Path(path)
df=pd.read_csv(dirPath)
#print(df.head())

# Set class-label from true/false to 0/1
df['class'] = df['class'].astype(int)

# Split into input and target variables
X = df.iloc[:, 2:]  # Remove the ID and Class columns
Y = df.iloc[:, 1]

# Scale data
x = X.values # returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
#scaler = preprocessing.StandardScaler()
#x_scaled = scaler.fit_transform(x)
x_scaled = min_max_scaler.fit_transform(x)
df_x_scaled = pd.DataFrame(x_scaled)
#print(df_x_scaled)

# Import test-data and scaling the data
pathTest = 'breast-cancer-diagnostic.shuf.tes.csv'
dirPathTest = pathlib.Path(pathTest)
df_test=pd.read_csv(dirPathTest)

xTest = df_test.iloc[:, 1:]  # Remove the ID and Class columns
x_test = xTest.values # returns a numpy array

min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x_test)

#scaler = preprocessing.StandardScaler()
#x_scaled = scaler.fit_transform(x_test)

df_test_normalized = pd.DataFrame(x_scaled)
#print(df_test_normalized)

def predict_knn(x_test, x_train, y_train, k_min=1, k_max=25):
    all_predictions = []
    for k in tqdm(range(k_min,k_max)):
        # Create KNN classifier
        knn = KNeighborsClassifier(n_neighbors=k,p=2)
        # Fit the classifier to the data
        knn.fit(x_train, y_train)
        # Predict on x_test
        prediction = knn.predict(x_test)
        all_predictions.append(prediction)
    return all_predictions

# Check the accuracy of given predictions on the test set y_test
def check_accuracy(y_test, predictions):
    ground_truth = y_test.to_list()
    size = len(ground_truth)
    results = []
    x = []

    for predict in predictions:
        count = 0
        for i, x in enumerate(ground_truth):
            if predict[i] == ground_truth[i]:
                count += 1
        results.append(count / size)
        bestIdx = results.index(np.max(results))
    return results, bestIdx

r = []
idx = []

print("\nTRAINING USING KNN")
for testSize in range(10,50,5):
    X_train, X_test, Y_train, Y_test = train_test_split(df_x_scaled, Y, test_size=testSize/100, random_state=35)

    # KNN
    all_predictions = predict_knn(X_test, X_train, Y_train,1,25)
    results, bestIdx = check_accuracy(Y_test, all_predictions)
    print("\nTest size = ", testSize/100)
    print(results)
    testSize = testSize/100
    bestResult = np.max(results)
    r.append(results)

bestOverallResult = np.max(r)
df = pd.DataFrame(data=r)
idxs = df.stack().index[np.argmax(df.values)]
print("The best indexes (testsize, k): ", idxs)

fig = df.plot(title='Training with different k and test sizes', ylabel='Accuracy',xlabel='K')
fig.legend(["10","15","20","25","30","35","40","45"])
#fig.suptitle('SVM with different test sizes', fontsize=14)
#df.xlabel('Test sie', fontsize=14)
#df.ylabel('Accuracy', fontsize=14)
#print("Max accuracy = ", np.max(r), "with testsize = ", best_testSize)

from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
print(idxs[0]+1)

cv_ = int((idxs[0]+1))
testSize = 100/cv_
clf = KNeighborsClassifier(n_neighbors=idxs[1]+1,metric = 'euclidean')
scores = cross_val_score(clf, X, Y, cv=cv_)
x = range(1,cv_+1)

fig = plt.figure()
plt.scatter(x,scores)
fig.suptitle('SVM cross validation with test size ' + str(testSize) + '% with euclidean distance', fontsize=14)
plt.xlabel('Iteration', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
print("Max accuracy = ", np.max(scores))

from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
print(idxs[0]+1)

cv_ = int((idxs[0]+1))
testSize = 100/cv_
clf = KNeighborsClassifier(n_neighbors=idxs[1]+1,metric = 'manhattan')
scores = cross_val_score(clf, X, Y, cv=cv_)
x = range(1,cv_+1)

fig = plt.figure()
plt.scatter(x,scores)
fig.suptitle('SVM cross validation with test size ' + str(testSize) + '% with manhattan distance', fontsize=14)
plt.xlabel('Iteration', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
print("Max accuracy = ", np.max(scores))

cv_ = int((idxs[0]+1))
testSize = 100/cv_
clf = KNeighborsClassifier(n_neighbors=idxs[1]+1,metric = 'chebyshev')
scores = cross_val_score(clf, X, Y, cv=cv_)
x = range(1,cv_+1)

fig = plt.figure()
plt.scatter(x,scores)
fig.suptitle('SVM cross validation with test size ' + str(testSize) + '% with chebyshev distance', fontsize=14)
plt.xlabel('Iteration', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
print("Max accuracy = ", np.max(scores))

cv_ = int((idxs[0]+1))
testSize = 100/cv_
clf = KNeighborsClassifier(n_neighbors=idxs[1]+1,metric = 'minkowski')
scores = cross_val_score(clf, X, Y, cv=cv_)
x = range(1,cv_+1)

fig = plt.figure()
plt.scatter(x,scores)
fig.suptitle('SVM cross validation with test size ' + str(testSize) + '% with minkowski distance', fontsize=14)
plt.xlabel('Iteration', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
print("Max accuracy = ", np.max(scores))